"""
AI Council - Session Logging
Structured JSONL logging for fine-tuning data collection.
"""

import json
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, asdict


@dataclass
class LogEntry:
    """A single log entry for the session."""
    timestamp: str
    session_id: str
    stage: str
    agent_id: str
    persona_id: Optional[str]
    persona_name: Optional[str]
    ram_mode: str
    input_hash: str
    input_tokens: int
    input_text: str  # Full input text for debugging
    output_text: str
    output_tokens: int
    memory_usage_mb: int
    user_vote: Optional[int] = None
    user_feedback: Optional[str] = None
    ai_score: Optional[float] = None
    metadata: Optional[Dict[str, Any]] = None


class SessionLogger:
    """
    Handles structured logging for council sessions.
    
    Logs are stored as JSONL (one JSON object per line) for:
    - Easy streaming writes
    - Simple parsing for fine-tuning
    - Efficient storage
    """
    
    def __init__(self, sessions_dir: Path, session_id: str, ram_mode: str):
        """
        Initialize session logger.
        
        Args:
            sessions_dir: Directory to store session logs.
            session_id: Unique session identifier.
            ram_mode: Current RAM mode (16GB/32GB).
        """
        self.sessions_dir = Path(sessions_dir)
        self.session_id = session_id
        self.ram_mode = ram_mode
        self.log_file = self.sessions_dir / f"{session_id}.jsonl"
        
        # Ensure directory exists
        self.sessions_dir.mkdir(parents=True, exist_ok=True)
        
        # In-memory buffer for current session
        self._entries: List[LogEntry] = []
    
    @staticmethod
    def compute_hash(text: str) -> str:
        """Compute SHA256 hash of input text."""
        return hashlib.sha256(text.encode('utf-8')).hexdigest()[:16]
    
    @staticmethod
    def estimate_tokens(text: str) -> int:
        """Estimate token count (rough approximation: ~4 chars per token)."""
        return len(text) // 4
    
    def log(
        self,
        stage: str,
        agent_id: str,
        input_text: str,
        output_text: str,
        persona_id: Optional[str] = None,
        persona_name: Optional[str] = None,
        memory_usage_mb: int = 0,
        user_vote: Optional[int] = None,
        user_feedback: Optional[str] = None,
        ai_score: Optional[float] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> LogEntry:
        """
        Log a pipeline event.
        
        Args:
            stage: Pipeline stage (worker_draft, synth_questions, etc.)
            agent_id: Agent identifier (worker_1, synthesizer, etc.)
            input_text: Input provided to the agent.
            output_text: Output generated by the agent.
            persona_id: Optional persona UUID.
            persona_name: Optional persona display name.
            memory_usage_mb: Current memory usage in MB.
            user_vote: Optional user vote (1, 2, 3, or None).
            user_feedback: Optional user feedback text.
            ai_score: Optional AI-assigned score.
            metadata: Optional additional metadata.
        
        Returns:
            The created LogEntry.
        """
        entry = LogEntry(
            timestamp=datetime.utcnow().isoformat() + "Z",
            session_id=self.session_id,
            stage=stage,
            agent_id=agent_id,
            persona_id=persona_id,
            persona_name=persona_name,
            ram_mode=self.ram_mode,
            input_hash=self.compute_hash(input_text),
            input_tokens=self.estimate_tokens(input_text),
            input_text=input_text,  # Include full input text for debugging
            output_text=output_text,
            output_tokens=self.estimate_tokens(output_text),
            memory_usage_mb=memory_usage_mb,
            user_vote=user_vote,
            user_feedback=user_feedback,
            ai_score=ai_score,
            metadata=metadata
        )
        
        # Add to buffer
        self._entries.append(entry)
        
        # Write to file
        self._write_entry(entry)
        
        return entry
    
    def _write_entry(self, entry: LogEntry):
        """Write a single entry to the log file."""
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(asdict(entry), ensure_ascii=False) + '\n')
    
    def update_entry(self, index: int, **updates):
        """
        Update an existing entry (e.g., adding user vote after the fact).
        
        Note: This rewrites the entire file, so use sparingly.
        """
        if 0 <= index < len(self._entries):
            entry = self._entries[index]
            for key, value in updates.items():
                if hasattr(entry, key):
                    setattr(entry, key, value)
            
            # Rewrite file
            self._rewrite_file()
    
    def _rewrite_file(self):
        """Rewrite the entire log file from buffer."""
        with open(self.log_file, 'w', encoding='utf-8') as f:
            for entry in self._entries:
                f.write(json.dumps(asdict(entry), ensure_ascii=False) + '\n')
    
    def get_entries(self, stage: Optional[str] = None) -> List[LogEntry]:
        """
        Get log entries, optionally filtered by stage.
        
        Args:
            stage: Optional stage to filter by.
        
        Returns:
            List of matching log entries.
        """
        if stage:
            return [e for e in self._entries if e.stage == stage]
        return self._entries.copy()

    def find_entry(self, stage: str, agent_id: str, input_hash: str) -> Optional[LogEntry]:
        """Find a matching entry by stage, agent, and input hash."""
        for entry in self._entries:
            if entry.stage == stage and entry.agent_id == agent_id and entry.input_hash == input_hash:
                return entry
        return None

    def has_entry(self, stage: str, agent_id: str, input_hash: str) -> bool:
        """Check if a matching entry exists by stage, agent, and input hash."""
        return self.find_entry(stage, agent_id, input_hash) is not None
    
    def get_session_summary(self) -> Dict[str, Any]:
        """Get a summary of the session for export."""
        stages = {}
        for entry in self._entries:
            if entry.stage not in stages:
                stages[entry.stage] = []
            stages[entry.stage].append({
                "agent_id": entry.agent_id,
                "persona_name": entry.persona_name,
                "output_tokens": entry.output_tokens,
                "ai_score": entry.ai_score,
                "user_vote": entry.user_vote
            })
        
        return {
            "session_id": self.session_id,
            "ram_mode": self.ram_mode,
            "total_entries": len(self._entries),
            "stages": stages,
            "has_user_votes": any(e.user_vote is not None for e in self._entries),
            "has_ai_scores": any(e.ai_score is not None for e in self._entries)
        }
    
    @classmethod
    def load_session(cls, log_file: Path) -> List[Dict[str, Any]]:
        """
        Load a session from a log file.
        
        Args:
            log_file: Path to the JSONL log file.
        
        Returns:
            List of log entries as dictionaries.
        """
        entries = []
        with open(log_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    entries.append(json.loads(line))
        return entries
    
    @classmethod
    def export_for_finetuning(
        cls,
        sessions_dir: Path,
        export_file: Path,
        min_user_votes: int = 0,
        include_stages: Optional[List[str]] = None
    ) -> int:
        """
        Export sessions for fine-tuning.
        
        Args:
            sessions_dir: Directory containing session logs.
            export_file: Output file path.
            min_user_votes: Minimum user votes required to include session.
            include_stages: Optional list of stages to include.
        
        Returns:
            Number of entries exported.
        """
        all_entries = []
        
        for log_file in sessions_dir.glob("*.jsonl"):
            entries = cls.load_session(log_file)
            
            # Check minimum votes
            vote_count = sum(1 for e in entries if e.get("user_vote") is not None)
            if vote_count < min_user_votes:
                continue
            
            # Filter stages if specified
            if include_stages:
                entries = [e for e in entries if e.get("stage") in include_stages]
            
            all_entries.extend(entries)
        
        # Write export file
        with open(export_file, 'w', encoding='utf-8') as f:
            for entry in all_entries:
                f.write(json.dumps(entry, ensure_ascii=False) + '\n')
        
        return len(all_entries)

